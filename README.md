# Remote Sensing Image Captioning avec ResNet50 + Transformer

## Vue d'ensemble

Ce projet impl√©mente un syst√®me de g√©n√©ration automatique de descriptions (captions) pour des images de t√©l√©d√©tection (remote sensing). Il utilise une architecture encoder-decoder bas√©e sur ResNet50 pour l'extraction de features visuelles et un Transformer pour la g√©n√©ration de texte.

### Objectif
G√©n√©rer automatiquement des descriptions textuelles pr√©cises pour des images satellites et a√©riennes du dataset RSICD (Remote Sensing Image Captioning Dataset).


##  Architecture du mod√®le

### Encoder : ResNet50 pr√©-entra√Æn√©
- **Backbone** : ResNet-50 pr√©-entra√Æn√© sur ImageNet
- **Extraction de features** : Couches convolutionnelles (jusqu'√† la derni√®re couche avant FC)
- **Pooling** : Pooling (1x1)
- **Projection** : 49 vecteurs de 256 dimensions
- **Fine-tuning** : Les 2 derniers blocs ResNet sont entra√Ænables

### Decoder : Transformer
- **Architecture** : Transformer Decoder (6 couches)
- **Dimensions** :
  - Embedding : 256
  - Decoder : 512
  - Attention heads : 8
- **Positional Encoding** : Encodage sinuso√Ødal pour les positions des tokens
- **M√©canisme d'attention** : Multi-head attention avec masque causal
- **Dropout** : 0.1

### Param√®tres du mod√®le
- **Total de param√®tres** : ~50,5M
- **Param√®tres entra√Ænables** : ~49,1M
- **Param√®tres gel√©s** : ~1,4M


## Dataset : RSICD

Le **Remote Sensing Image Captioning Dataset (RSICD)** contient des images satellites avec descriptions textuelles.

### Statistiques
- **Total d'images** : 10 921 images
- **Distribution** :
  - Train : 8 734 images (80%)
  - Validation : 1 094 images (10%)
  - Test : 1 093 images (10%)

### Caract√©ristiques des captions
- **Nombre total de captions** : 43 670 (pour le train set)
- **Moyenne de captions par image** : ~5
- **Longueur moyenne des captions** : Variable (max observ√© ~36 tokens)
- **Taille du vocabulaire** : 1 434 mots (fr√©quence minimale : 3)

### Preprocessing
- **R√©solution des images** : 224√ó224 pixels
- **Normalisation** : Moyenne et √©cart-type ImageNet
  - Mean: [0.485, 0.456, 0.406]
  - Std: [0.229, 0.224, 0.225]
- **Tokens sp√©ciaux** : `<PAD>`, `<START>`, `<END>`, `<UNK>`


## üìà R√©sultats d'√©valuation

### M√©triques sur le Test Set

| M√©trique | Score | Description |
|----------|-------|-------------|
| **BLEU-1** | 0.6448 | Pr√©cision des unigrammes |
| **BLEU-2** | 0.4762 | Pr√©cision des bigrammes |
| **BLEU-3** | 0.3758 | Pr√©cision des trigrammes |
| **BLEU-4** | 0.3025 | Pr√©cision des 4-grammes |
| **METEOR** | 0.2605 | M√©trique alignement s√©mantique |
| **ROUGE-L** | 0.4771 | Longest Common Subsequence |
| **CIDEr** | 0.8326 | Consensus-based metric |



## Entra√Ænement

### Hyperparam√®tres
```python
Epochs: 50
Batch size: 64 (train), 128 (val), 1 (test)
Optimizer: Adam
  - Encoder LR: 1e-4
  - Decoder LR: 4e-4
Scheduler: ReduceLROnPlateau (factor=0.5, patience=3)
Loss function: CrossEntropyLoss (ignore PAD tokens)
Gradient clipping: max_norm=5.0
